package edu.dartmouthcs.mltoolkit.ServiceControllers.AudioLib;

import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.OutputStreamWriter;
import java.io.RandomAccessFile;

import edu.dartmouthcs.sensorlab.MLToolkitInterface;
import edu.dartmouthcs.sensorlab.MLToolkitInterface.acc_config;
import edu.dartmouthcs.sensorlab.MLToolkitInterfaceAudio;
//import edu.dartmouthcs.sensorlab.MLToolkitInterface.acc_config;

import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.MediaRecorder;
import android.os.Bundle;
import android.os.Handler;
import android.os.Message;
import android.util.Log;
import edu.dartmouthcs.UtilLibs.MyDataTypeConverter;
import edu.dartmouthcs.mltoolkit.Ml_Toolkit_Application;
import edu.dartmouthcs.mltoolkit.ServiceControllers.AudioLib.AudioService;
import edu.dartmouthcs.mltoolkit.Storage.ML_toolkit_object;

public class RehearsalAudioRecorder
{

	public final int AUDIO_SAMPLES_REQUIRED=512;
	public final int AUDIO_SAMPLERATE=8192;
	private MLToolkitInterface mlt;
	//private MLToolkitInterfaceAudio mlt;
	private Ml_Toolkit_Application appState;

	public class audio_config{
		public int samplingRate;
		public int frameLength;
		public int windowLength;
		public int mfccLength;

		// void (*callback)(int)

		public audio_config(int sr, int fl, int wl, int ml){
			samplingRate = sr;
			frameLength = fl;
			windowLength = wl;
			mfccLength = ml;

		}		
	}


	/**
	 * INITIALIZING : recorder is initializing;
	 * READY : recorder has been initialized, recorder not yet started
	 * RECORDING : recording
	 * ERROR : reconstruction needed
	 * STOPPED: reset needed
	 */
	public enum State {INITIALIZING, READY, RECORDING, ERROR, STOPPED};

	public static final boolean RECORDING_UNCOMPRESSED = true;
	public static final boolean RECORDING_COMPRESSED = false;

	// The interval in which the recorded samples are output to the file
	// Used only in uncompressed mode
	private static final int TIMER_INTERVAL = 120;

	// Toggles uncompressed recording on/off; RECORDING_UNCOMPRESSED / RECORDING_COMPRESSED
	private boolean 		 rUncompressed;

	// Recorder used for uncompressed recording
	private AudioRecord 	 aRecorder = null;
	// Recorder used for compressed recording
	private MediaRecorder	 mRecorder = null;

	// Stores current amplitude (only in uncompressed mode)
	private int				 cAmplitude= 0;
	// Output file path
	private String			 fPath = null;

	// Recorder state; see State
	private State			 state;

	// File writer (only in uncompressed mode)
	//private RandomAccessFile fWriter;

	private static OutputStreamWriter fWriter = null; 
	private FileOutputStream fOut;

	// Number of channels, sample rate, sample size(size in bits), buffer size, audio source, sample size(see AudioFormat)
	private short 			 nChannels;
	private int				 sRate;
	private short			 bSamples;
	private int				 bufferSize;
	private int				 aSource;
	private int				 aFormat;

	// Number of frames written to file on each output(only in uncompressed mode)
	private int				 framePeriod;

	// Buffer for output(only in uncompressed mode)
	//private byte[] 			 buffer;
	private short[] 			 buffer;
	private short[] 			 temp_buffer;
	private short[] 			 normalize_temp_buffer;

	// Number of bytes written to file after header(only in uncompressed mode)
	// after stop() is called, this size is written to the header/data chunk in the wave file
	private int				 payloadSize;
	private int 			 updateFlag;
	private AudioService ASobj;
	private ML_toolkit_object AudioObject;

	private ML_toolkit_object audio_features;
	private ML_toolkit_object audio_inference;

	//raw audio data buffer
	private final int rawAudioBufferSize = 1600;
	private short[][] rawAudioBuffer = new short[rawAudioBufferSize][512]; //HARD CODING: 512 is the hong's data element size
	private long[] rawAudioBufferTimestamps = new long[rawAudioBufferSize];
	private int rawAudioIndexBufferWrite = 0;
	private int rawAudioIndexDBWrite = 0;
	private final int MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP = rawAudioBufferSize/20; 
	private boolean[] rawAudioOnStatus = new boolean[rawAudioBufferSize/20];

	//no. of elements in the buffer
	private int no_elements_in_buffer = 0;
	private int no_of_inference_results_write = 0;
	private int no_of_inference_results_read = 0;
	private boolean first_start = false;

	//temp timestammp
	private long temp_timestamp = 0;

	//variables for not recording audio samples
	public static final int NO_SAMPLES_TO_IGNORE_WHEN_VOICE = 2; //means 2 frames before and after
	public static final int AMOUNT_OF_BUFFERING_BEFORE_AUDIO_WRITE = 10; //no of inference results to buffer before the write happens

	//buffer for inference results
	//normally size of MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP to ensure we don't overrun
	private boolean[] voicingInferredStatus = new boolean[MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP];
	private int number_of_inferece_results = 0;

	private int no_of_inference_results_voice_read = 0;
	private int no_of_inference_results_voice_write = 0;

	private String[] inferred_state_buffer = new String[MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP];

	//flag for the first one where it will not try to find the 
	//last NO_SAMPLES_TO_IGNORE_WHEN_VOICE number of samples to
	//ignore
	private boolean isFirstBuffering = true;
	
	//voice write counter
	//should be zero to start writing raw audio again
	private int no_of_inferences_before_writing_audio = 0;



	private Handler audioCallbackHandler;

	/**
	 * 
	 * Returns the state of the recorder in a RehearsalAudioRecord.State typed object.
	 * Useful, as no exceptions are thrown.
	 * 
	 * @return recorder state
	 */
	public State getState()
	{
		return state;
	}

	/*
	 * 
	 * Method used for recording.
	 * 
	 */
	private AudioRecord.OnRecordPositionUpdateListener updateListener = new AudioRecord.OnRecordPositionUpdateListener()
	{
		public void onPeriodicNotification(AudioRecord recorder)
		{
			aRecorder.read(buffer, 0, buffer.length); // Fill buffer
			try
			{ 
				//fWriter.write(buffer); // Write buffer to file
				//fWriter.write(""+System.currentTimeMillis()+"\n");
				//flush is in the audio callback

				//fWriter.flush();
				//payloadSize += buffer.length;

				//System.arraycopy(buffer,0,normalize_temp_buffer,0,buffer.length);

				//for(int i = 0; i<512; i++)
				//buffer[i] = (short)Math.round(((double)buffer[i])*0.8);



				appState.mlt.getAudioSample(buffer);


				//Log.i("RawAudioWrite" , "Raw Audio Sensing " + rawAudioIndexBufferWrite);
				//if(appState.rawAudioOn){
				//will roll back to the first one
				//	AudioObject =  new ML_toolkit_object(System.currentTimeMillis()+appState.timeOffset, 0, MyDataTypeConverter.toByta(buffer));
				//		appState.ML_toolkit_buffer.insert(AudioObject);//inserting into the buffer
				//}
				//else // buffer the data and wait for inference results
				//{

				//rawAudioBuffer[rawAudioIndexBufferWrite] = buffer;
				System.arraycopy(buffer,0,rawAudioBuffer[rawAudioIndexBufferWrite],0,buffer.length);
				rawAudioBufferTimestamps[rawAudioIndexBufferWrite] = System.currentTimeMillis()+appState.timeOffset;
				rawAudioIndexBufferWrite = (rawAudioIndexBufferWrite+1)%rawAudioBufferSize;  

				//}


				payloadSize += buffer.length;
				if(updateFlag%20==0)
					//means whether rawAudioOnStatus was ON/OFF for each 20 raw audio sensing results
					//that one of them corresponds to one inference
				{
					rawAudioOnStatus[no_of_inference_results_write]=appState.rawAudioOn;
					no_of_inference_results_write = (no_of_inference_results_write + 1)%MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP;
				}
				updateFlag++; //means no of recods


				appState.audio_no_of_records = payloadSize;

				//updateFlag++;
				if (updateFlag%28125 == 1){
					//ASobj.no_of_records = payloadSize;

					ASobj.updateNotificationArea();
				}

				/*if (bSamples == 16)
				{
					for (int i=0; i<buffer.length/2; i++)
					{ // 16bit sample size
						short curSample = getShort(buffer[i*2], buffer[i*2+1]);
						if (curSample > cAmplitude)
						{ // Check amplitude
							cAmplitude = curSample;
						}
					}
				}
				else
				{ // 8bit sample size
					for (int i=0; i<buffer.length; i++)
					{
						if (buffer[i] > cAmplitude)
						{ // Check amplitude
							cAmplitude = buffer[i];
						}
					}
				}*/
			}
			catch (Exception e)
			{
				Log.e(RehearsalAudioRecorder.class.getName(), "Error occured in updateListener, recording is aborted" +e.toString());
				stop();
			}
		}

		public void onMarkerReached(AudioRecord recorder)
		{
			// NOT USED
		}
	};

	/** 
	 * 
	 * 
	 * Default constructor
	 * 
	 * Instantiates a new recorder, in case of compressed recording the parameters can be left as 0.
	 * In case of errors, no exception is thrown, but the state is set to ERROR
	 * 
	 */ 
	public RehearsalAudioRecorder(Ml_Toolkit_Application apppState, AudioService obj, boolean uncompressed, int audioSource, int sampleRate, int channelConfig,
			int audioFormat)
	{
		this.ASobj = obj;
		this.appState = apppState;
		try
		{
			rUncompressed = uncompressed;
			if (rUncompressed)
			{ // RECORDING_UNCOMPRESSED
				if (audioFormat == AudioFormat.ENCODING_PCM_16BIT)
				{
					bSamples = 16;
				}
				else
				{
					bSamples = 8;
				}

				if (channelConfig == AudioFormat.CHANNEL_CONFIGURATION_MONO)
				{
					nChannels = 1;
				}
				else
				{
					nChannels = 2;
				}

				aSource = audioSource;
				sRate   = sampleRate;
				aFormat = audioFormat;

				framePeriod = 512;//sampleRate * TIMER_INTERVAL / 1000;
				//bufferSize = framePeriod * 2 * bSamples * nChannels / 8;
				
				//bufferSize = framePeriod * 25 * bSamples * nChannels / 8;
				bufferSize = framePeriod * 5 * bSamples * nChannels / 8;
				
				Log.i("BUFFFFER SIZEEEEEEEE", "Buffer size" + bufferSize);
				if (bufferSize < AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat))
				{ // Check to make sure buffer size is not smaller than the smallest allowed one 
					bufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat);
					// Set frame period and timer interval accordingly
					framePeriod = bufferSize / ( 2 * bSamples * nChannels / 8 );
					Log.w(RehearsalAudioRecorder.class.getName(), "Increasing buffer size to " + Integer.toString(bufferSize));
				}

				aRecorder = new AudioRecord(audioSource, sampleRate, channelConfig, audioFormat, bufferSize);
				if (aRecorder.getState() != AudioRecord.STATE_INITIALIZED)
					throw new Exception("AudioRecord initialization failed");
				aRecorder.setRecordPositionUpdateListener(updateListener);
				aRecorder.setPositionNotificationPeriod(framePeriod);
				this.updateFlag = 0;


				//handler and Ml toolkit initialization
				audioCallbackHandler = new Handler(){
					//@Override
					public void handleMessage(Message msg){
						super.handleMessage(msg);
						Bundle b = msg.getData();
						ASobj.prev_inferred_audio_Status = ASobj.inferred_audio_Status;
						ASobj.inferred_audio_Status = b.getString("audio_inferred_result");

						//keeps record of whether the current inference is voice or not
						voicingInferredStatus[no_of_inference_results_voice_write] = ASobj.inferred_audio_Status.equals("voice");
						inferred_state_buffer[no_of_inference_results_voice_write] = ASobj.inferred_audio_Status;
						no_of_inference_results_voice_write = (no_of_inference_results_voice_write  + 1)%MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP;


						//number of inference results records
						number_of_inferece_results = (number_of_inferece_results+1)%AMOUNT_OF_BUFFERING_BEFORE_AUDIO_WRITE;

						//Log.i("RawAudioWrite" , "Raw Audio Inference " + ASobj.inferred_audio_Status +" "+rawAudioIndexBufferWrite);
						//if(!appState.rawAudioOn){ // if raw audio is not on, then record data for "noise" only

						if(number_of_inferece_results == 0){
							Thread t = new Thread() {
								public void run() {
									//mResults = doSomethingExpensive();
									//mHandler.post(mUpdateResults);
									//if(!ASobj.prev_inferred_audio_Status.equals("voice"))


									//startWritingRawAudio(ASobj.inferred_audio_Status); //means don't 

									startWritingRawAudioBufferWrite(); //means don't 
								}
							};
							t.start();
						}




						//store state whether there is voice
						//smoothing code

						//if(!ASobj.prev_inferred_audio_Status.equals("voice") && !ASobj.prev_inferred_audio_Status.equals(ASobj.inferred_audio_Status)){
						if(!ASobj.prev_inferred_audio_Status.equals(ASobj.inferred_audio_Status)){
							if(!ASobj.prev_inferred_audio_Status.equals("Not Available"))
							{
								audio_inference =  new ML_toolkit_object(System.currentTimeMillis()+appState.timeOffset, 5, false, ASobj.prev_inferred_audio_Status);
								appState.ML_toolkit_buffer.insert(audio_inference);
							}

							audio_inference =  new ML_toolkit_object(System.currentTimeMillis()+appState.timeOffset, 5, true, ASobj.inferred_audio_Status);
							appState.ML_toolkit_buffer.insert(audio_inference);

							/*no_of_inference_results++;
							if(no_of_inference_results > 40)
								no_of_inference_results = 1;

							if(first_start == false && no_of_inference_results > 2)
							{
								first_start = true;
							}
							 */
							//}
							
							Log.i("Inferred Saved Status: ", ASobj.inferred_audio_Status);

						}





						audio_features =  new ML_toolkit_object(System.currentTimeMillis()+appState.timeOffset, 3, MyDataTypeConverter.toByta(b.getDoubleArray("audio_features")));
						appState.ML_toolkit_buffer.insert(audio_features);

						//Log.d(TAG, "Helllllllllllllllllo");
						//main_view.append(b.getString("callback_string"));
						//main_view.append("hi");

						//test code for jitter
						/*try {
							fWriter.flush();
						} catch (IOException e) {
							// TODO Auto-generated catch block
							e.printStackTrace();
						}*/
					}
				}; 

				//setcallback for audio
				appState.mlt.setAudioHandler(audioCallbackHandler);


				///Machine learning tool kit init
				//mlt = new MLToolkitInterfaceAudio(audioCallbackHandler); 
				//mlt = new MLToolkitInterface(audioCallbackHandler); 
				//edu.dartmouthcs.sensorlab.MLToolkitInterface.audio_config audio_Cfg = mlt.new audio_config(sampleRate,framePeriod, 20, 14);
				//edu.dartmouthcs.sensorlab.MLToolkitInterfaceAudio.audio_config audio_Cfg = mlt.new audio_config(sampleRate,framePeriod, 20, 14);
				//mlt.init(null, audio_Cfg, null);
				//mlt.init(acc_Cfg, audio_Cfg, null);


			} else
			{ // RECORDING_COMPRESSED
				mRecorder = new MediaRecorder();
				mRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);
				mRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
				mRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB);
			}
			cAmplitude = 0;
			fPath = null;
			state = State.INITIALIZING;
		} catch (Exception e)
		{
			if (e.getMessage() != null)
			{
				Log.e(RehearsalAudioRecorder.class.getName(), e.getMessage());
			}
			else
			{
				Log.e(RehearsalAudioRecorder.class.getName(), "Unknown error occured while initializing recording");
			}
			state = State.ERROR;
		}
	}

	public synchronized void startWritingRawAudioBufferWrite()
	{
		boolean storing = false;
		boolean isVoice = false;
		String inferred_stat;
		int j = 0;
		
		if(this.isFirstBuffering == true){
			//start from 2 (indexing starts at )
			j = NO_SAMPLES_TO_IGNORE_WHEN_VOICE;
			no_of_inference_results_voice_read = NO_SAMPLES_TO_IGNORE_WHEN_VOICE;
			this.isFirstBuffering = false;
		}

		for( ; j < AMOUNT_OF_BUFFERING_BEFORE_AUDIO_WRITE; j++){
			
			inferred_stat = inferred_state_buffer[no_of_inference_results_voice_read];
			isVoice = voicingInferredStatus[no_of_inference_results_voice_read];
			no_of_inference_results_voice_read = (no_of_inference_results_voice_read+1)%MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP;

			
			
			//if(!this.isFirstBuffering && j<NO_SAMPLES_TO_IGNORE_WHEN_VOICE){ 
			storing = false;
			
			if(isVoice == true)
				this.no_of_inferences_before_writing_audio = 2*NO_SAMPLES_TO_IGNORE_WHEN_VOICE + 1;
			
			//if(inferred_stat.equals("noise") || (!inferred_stat.equals("silence") && rawAudioOnStatus[no_of_inference_results_read]))
				//if(true)
				//if(false)
			
			if( (this.no_of_inferences_before_writing_audio == 0 || rawAudioOnStatus[no_of_inference_results_read]) && !inferred_state_buffer[no_of_inference_results_read].equals("silence"))
			{
				storing = true;

				for(int i = 0; i<20; i++)
				{	
					
					temp_buffer = rawAudioBuffer[rawAudioIndexDBWrite];
					// - rawAudioIndexBufferWrite));
					temp_timestamp = rawAudioBufferTimestamps[rawAudioIndexDBWrite];// = System.currentTimeMillis()+appState.timeOffset;

					//Log.i("RawAudioWrite" , "rawAudioIndexDBWrite " + temp_buffer.toString() + " " + buffer.toString() + " " 
					//	+ rawAudioBuffer[rawAudioIndexDBWrite].length);

					rawAudioIndexDBWrite = (rawAudioIndexDBWrite+1)%rawAudioBufferSize;
					AudioObject =  new ML_toolkit_object(temp_timestamp, 0, MyDataTypeConverter.toByta(temp_buffer));
					//Log.i("RawAudioWrite" , "Temp buffer size: " + rawAudioBuffer[rawAudioIndexDBWrite].length);
					appState.ML_toolkit_buffer.insert(AudioObject);//inserting into the buffer
				}
				
				if(this.no_of_inferences_before_writing_audio != 0 && rawAudioOnStatus[no_of_inference_results_read])
					this.no_of_inferences_before_writing_audio--;

			}
			else //means skip the frames from recording
			{				
				
				rawAudioIndexDBWrite = (rawAudioIndexDBWrite+20)%rawAudioBufferSize;
				
				if(this.no_of_inferences_before_writing_audio != 0)
					this.no_of_inferences_before_writing_audio--;
				
			}//}

			
			//if(this.isFirstBuffering == true)

			
			Log.i("RawAudioWrite" , "Raw Audio Write: " + rawAudioIndexDBWrite + " " + storing + " " + inferred_state_buffer[no_of_inference_results_read] + "  ::  isVoice " + 
					voicingInferredStatus[no_of_inference_results_read]);
			no_of_inference_results_read = (no_of_inference_results_read+1)%MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP;
			
		}
	}


	public synchronized void  startWritingRawAudio(String inferred_stat)
	{
		boolean storing = false;

		if(inferred_stat.equals("noise") || (!inferred_stat.equals("silence") && rawAudioOnStatus[no_of_inference_results_read]))
			//if(true)
			//if(false)
		{
			storing = true;

			for(int i = 0; i<20; i++)
			{				
				temp_buffer = rawAudioBuffer[rawAudioIndexDBWrite];
				// - rawAudioIndexBufferWrite));
				temp_timestamp = rawAudioBufferTimestamps[rawAudioIndexDBWrite];// = System.currentTimeMillis()+appState.timeOffset;

				//Log.i("RawAudioWrite" , "rawAudioIndexDBWrite " + temp_buffer.toString() + " " + buffer.toString() + " " 
				//	+ rawAudioBuffer[rawAudioIndexDBWrite].length);

				rawAudioIndexDBWrite = (rawAudioIndexDBWrite+1)%rawAudioBufferSize;
				AudioObject =  new ML_toolkit_object(temp_timestamp, 0, MyDataTypeConverter.toByta(temp_buffer));
				//Log.i("RawAudioWrite" , "Temp buffer size: " + rawAudioBuffer[rawAudioIndexDBWrite].length);
				appState.ML_toolkit_buffer.insert(AudioObject);//inserting into the buffer
			}
		}
		else //means skip the frames from recording
			rawAudioIndexDBWrite = (rawAudioIndexDBWrite+20)%rawAudioBufferSize;

		no_of_inference_results_read = (no_of_inference_results_read+1)%MAXIMUM_NO_OF_INFERENCE_RESULT_BEFORE_ROLL_UP;
		Log.i("RawAudioWrite" , "Raw Audio Write: " + rawAudioIndexDBWrite + " " + storing + " " + inferred_stat);
	}

	/**
	 * Sets output file path, call directly after construction/reset.
	 *  
	 * @param output file path
	 * 
	 */
	public void setOutputFile(String argPath)
	{
		try
		{
			if (state == State.INITIALIZING)
			{
				fPath = argPath;
				if (!rUncompressed)
				{
					mRecorder.setOutputFile(fPath);
				}
			}
		}
		catch (Exception e)
		{
			if (e.getMessage() != null)
			{
				Log.e(RehearsalAudioRecorder.class.getName(), e.getMessage());
			}
			else
			{
				Log.e(RehearsalAudioRecorder.class.getName(), "Unknown error occured while setting output path");
			}
			state = State.ERROR;
		}
	}

	/**
	 * 
	 * Returns the largest amplitude sampled since the last call to this method.
	 * 
	 * @return returns the largest amplitude since the last call, or 0 when not in recording state. 
	 * 
	 */
	public int getMaxAmplitude()
	{
		if (state == State.RECORDING)
		{
			if (rUncompressed)
			{
				int result = cAmplitude;
				cAmplitude = 0;
				return result;
			}
			else
			{
				try
				{
					return mRecorder.getMaxAmplitude();
				}
				catch (IllegalStateException e)
				{
					return 0;
				}
			}
		}
		else
		{
			return 0;
		}
	}


	/**
	 * 
	 * Prepares the recorder for recording, in case the recorder is not in the INITIALIZING state and the file path was not set
	 * the recorder is set to the ERROR state, which makes a reconstruction necessary.
	 * In case uncompressed recording is toggled, the header of the wave file is written.
	 * In case of an exception, the state is changed to ERROR
	 * 	 
	 */
	public void prepare()
	{
		try
		{
			if (state == State.INITIALIZING)
			{
				if (rUncompressed)
				{
					if ((aRecorder.getState() == AudioRecord.STATE_INITIALIZED) & (fPath != null))
					{
						/*try{
							fOut = new FileOutputStream(fPath);
							fWriter = new  OutputStreamWriter(fOut);
						}
						catch(Exception ex){}*/

						/*
						// write file header

						fWriter = new RandomAccessFile(fPath, "rw");

						fWriter.setLength(0); // Set file length to 0, to prevent unexpected behavior in case the file already existed
						fWriter.writeBytes("RIFF");
						fWriter.writeInt(0); // Final file size not known yet, write 0 
						fWriter.writeBytes("WAVE");
						fWriter.writeBytes("fmt ");
						fWriter.writeInt(Integer.reverseBytes(16)); // Sub-chunk size, 16 for PCM
						fWriter.writeShort(Short.reverseBytes((short) 1)); // AudioFormat, 1 for PCM
						fWriter.writeShort(Short.reverseBytes(nChannels));// Number of channels, 1 for mono, 2 for stereo
						fWriter.writeInt(Integer.reverseBytes(sRate)); // Sample rate
						fWriter.writeInt(Integer.reverseBytes(sRate*bSamples*nChannels/8)); // Byte rate, SampleRate*NumberOfChannels*BitsPerSample/8
						fWriter.writeShort(Short.reverseBytes((short)(nChannels*bSamples/8))); // Block align, NumberOfChannels*BitsPerSample/8
						fWriter.writeShort(Short.reverseBytes(bSamples)); // Bits per sample
						fWriter.writeBytes("data");
						fWriter.writeInt(0); // Data chunk size not known yet, write 0
						 */

						//buffer = new byte[framePeriod*bSamples/8*nChannels];
						buffer = new short[framePeriod*bSamples/16*nChannels];
						temp_buffer = new short[framePeriod*bSamples/16*nChannels];
						normalize_temp_buffer = new short[framePeriod*bSamples/16*nChannels];
						state = State.READY;
					}
					else
					{
						Log.e(RehearsalAudioRecorder.class.getName(), "prepare() method called on uninitialized recorder");
						state = State.ERROR;
					}
				}
				else
				{
					mRecorder.prepare();
					state = State.READY;
				}
			}
			else
			{
				Log.e(RehearsalAudioRecorder.class.getName(), "prepare() method called on illegal state");
				release();
				state = State.ERROR;
			}
		}
		catch(Exception e)
		{
			if (e.getMessage() != null)
			{
				Log.e(RehearsalAudioRecorder.class.getName(), e.getMessage());
			}
			else
			{
				Log.e(RehearsalAudioRecorder.class.getName(), "Unknown error occured in prepare()");
			}
			state = State.ERROR;
		}
	}

	/**
	 * 
	 * 
	 *  Releases the resources associated with this class, and removes the unnecessary files, when necessary
	 *  
	 */
	public void release()
	{
		//end the current state in the db
		audio_inference =  new ML_toolkit_object(System.currentTimeMillis()+appState.timeOffset, 5, false, ASobj.inferred_audio_Status);
		appState.ML_toolkit_buffer.insert(audio_inference);

		audio_inference =  new ML_toolkit_object(System.currentTimeMillis()+appState.timeOffset, 5, true, "unknown");
		appState.ML_toolkit_buffer.insert(audio_inference);
		
		
		appState.audio_release = true;
		if (state == State.RECORDING)
		{
			stop();
		}
		else
		{
			if ((state == State.READY) & (rUncompressed))
			{
				/*try
				{
					fWriter.close(); // Remove prepared file
				}
				catch (IOException e)
				{
					Log.e(RehearsalAudioRecorder.class.getName(), "I/O exception occured while closing output file");
				}
				(new File(fPath)).delete();*/
			}
		}

		if (rUncompressed)
		{
			if (aRecorder != null)
			{
				aRecorder.release();

			}
		}
		else
		{
			if (mRecorder != null)
			{
				mRecorder.release();
			}
		}
	}

	/**
	 * 
	 * 
	 * Resets the recorder to the INITIALIZING state, as if it was just created.
	 * In case the class was in RECORDING state, the recording is stopped.
	 * In case of exceptions the class is set to the ERROR state.
	 * 
	 */
	public void reset()
	{
		try
		{
			if (state != State.ERROR)
			{
				release();
				fPath = null; // Reset file path
				cAmplitude = 0; // Reset amplitude
				if (rUncompressed)
				{
					aRecorder = new AudioRecord(aSource, sRate, nChannels+1, aFormat, bufferSize);
				}
				else
				{
					mRecorder = new MediaRecorder();
					mRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);
					mRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
					mRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB);
				}
				state = State.INITIALIZING;
			}
		}
		catch (Exception e)
		{
			Log.e(RehearsalAudioRecorder.class.getName(), e.getMessage());
			state = State.ERROR;
		}
	}

	/**
	 * 
	 * 
	 * Starts the recording, and sets the state to RECORDING.
	 * Call after prepare().
	 * 
	 */
	public void start()
	{
		if (state == State.READY)
		{
			if (rUncompressed)
			{
				payloadSize = 0;
				aRecorder.startRecording();
				aRecorder.read(buffer, 0, buffer.length);

				appState.audio_release = false;
			}
			else
			{
				mRecorder.start();
			}
			state = State.RECORDING;
		}
		else
		{
			Log.e(RehearsalAudioRecorder.class.getName(), "start() called on illegal state");
			state = State.ERROR;
		}
	}

	/**
	 * 
	 * 
	 *  Stops the recording, and sets the state to STOPPED.
	 * In case of further usage, a reset is needed.
	 * Also finalizes the wave file in case of uncompressed recording.
	 * 
	 */
	public void stop()
	{
		try{
		if (state == State.RECORDING)
		{
			if (rUncompressed)
			{
				aRecorder.stop();

				/*try
				{
					/*
					fWriter.seek(4); // Write size to RIFF header
					fWriter.writeInt(Integer.reverseBytes(36+payloadSize));

					fWriter.seek(40); // Write size to Subchunk2Size field
					fWriter.writeInt(Integer.reverseBytes(payloadSize));

					//if(fWriter != null)
						//fWriter.close();
				}
				catch(IOException e)
				{
					Log.e(RehearsalAudioRecorder.class.getName(), "I/O exception occured while closing output file");
					state = State.ERROR;
				}*/
			}
			else
			{
				mRecorder.stop();
			}
			state = State.STOPPED;
		}
		else
		{
			Log.e(RehearsalAudioRecorder.class.getName(), "stop() called on illegal state");
			state = State.ERROR;
		}}
		catch(Exception ex){}
	}

	/* 
	 * 
	 * Converts a byte[2] to a short, in LITTLE_ENDIAN format
	 * 
	 */
	private short getShort(byte argB1, byte argB2)
	{
		return (short)(argB1 | (argB2 << 8));
	}
}

